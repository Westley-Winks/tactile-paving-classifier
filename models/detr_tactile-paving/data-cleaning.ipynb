{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning\n",
    "I got the data with the following structure:\n",
    "```\n",
    "├── crowd4access-images\n",
    "│   ├── crowd4access-images\n",
    "│   │   ├── test\n",
    "|   |   |   |--image\n",
    "|   |   |   |   |--*.jpg\n",
    "|   |   |   |--label\n",
    "|   |   |   |   |--*.txt\n",
    "│   │   ├── trainval\n",
    "|   |   |   |--image\n",
    "|   |   |   |   |--*.jpg\n",
    "|   |   |   |--label\n",
    "|   |   |   |   |--*.txt\n",
    "```\n",
    "\n",
    "where each image file had a text file of the same name with annotations in the form:\n",
    "\n",
    "```\n",
    "class_name top_left_x top_left_y bottom_right_x bottom_right_y\n",
    "```\n",
    "\n",
    "in absolute pixel coordinates (not relative). The DETR model I am using expects a COCO format where there is a `.json` file with the form:\n",
    "\n",
    "```\n",
    "{\n",
    "    \"info\": {...},\n",
    "    \"licenses\": [...],\n",
    "    \"images\": [...],\n",
    "    \"annotations\": [...],\n",
    "    \"categories\": [...], <-- Not in Captions annotations\n",
    "    \"segment_info\": [...] <-- Only in Panoptic annotations\n",
    "}\n",
    "# from https://www.immersivelimit.com/tutorials/create-coco-annotations-from-scratch\n",
    "```\n",
    "\n",
    "where bounding box coordinates (placed in the annotations list) are relative.\n",
    "\n",
    "To convert, I read in each text file and converted the bounding box coordinates to the COCO format and put it all into a custom Python dictionary. I then dumped it as a `.json` file to complete the conversion to COCO format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_train_data = \"../data/trainval/image\" # for local\n",
    "path_to_test_data = \"../data/test/image\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert Data into COCO formatted Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_bbox_definition(left: int, top: int, right: int, bottom: int) -> list:\n",
    "    '''\n",
    "    Converts bounding box definition from:\n",
    "    \n",
    "    `class_name top_left_x top_left_y bottom_right_x bottom_right_y`\n",
    "\n",
    "    to the proper COCO formatting defined as:\n",
    "\n",
    "    `top_left_x top_left_y width height`\n",
    "\n",
    "    '''\n",
    "    top_left_x = left\n",
    "    top_left_y = top\n",
    "    width = right - left\n",
    "    height = bottom - top\n",
    "\n",
    "    bbox = [top_left_x, top_left_y, width, height]\n",
    "    return bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert2coco(path: str) -> dict:\n",
    "    '''\n",
    "    Creates the correct label formatting for the model to train on defined as a dictionary with keys `image_id` and `annotations` where `annotations` is a list of dictionaries with each dictionary being a COCO object annotation\n",
    "    '''\n",
    "\n",
    "    d = {\n",
    "        \"info\": {\n",
    "            \"description\": \"Tactile Paving Dataset from Crowd4Access\",\n",
    "            \"year\": 2022\n",
    "        },\n",
    "\n",
    "        \"licenses\": [\n",
    "            {\n",
    "                \"id\": 0,\n",
    "                \"name\": \"Attribution-ShareAlike 4.0 International\",\n",
    "                \"url\": \"https://creativecommons.org/licenses/by-sa/4.0/legalcode\"\n",
    "            }\n",
    "        ],\n",
    "\n",
    "        \"images\": [],\n",
    "\n",
    "        \"annotations\": [],\n",
    "\n",
    "        \"categories\": [\n",
    "            {\n",
    "                \"id\": 0,\n",
    "                \"name\": \"tactile_paving\",\n",
    "                \"supercategory\": \"tactile_paving\"\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    i = 0 # counter for creating new image ids\n",
    "    j = 0 # counter for annotation ids\n",
    "\n",
    "    for item in os.listdir(path + \"/image\"): # look at every image in path\n",
    "        \n",
    "        filename = item.split(\".\")[0] # split on file extension and just get id\n",
    "        \n",
    "        with open(f\"{path}/label/{filename}.txt\", \"r\") as f:\n",
    "            # ANNOTATIONS\n",
    "            for line in f.readlines():\n",
    "                split_line = line.split(\" \")\n",
    "                \n",
    "                # each bbox is defined as (class left top right bottom) as a new line in the corresponding .txt file\n",
    "\n",
    "                image_class = split_line[0].strip()\n",
    "                bbox_left = int(split_line[1].strip())\n",
    "                bbox_top = int(split_line[2].strip())\n",
    "                bbox_right = int(split_line[3].strip())\n",
    "                bbox_bottom = int(split_line[4].strip(\"\\n\"))\n",
    "\n",
    "                new_bbox = convert_bbox_definition(\n",
    "                    bbox_left,\n",
    "                    bbox_top,\n",
    "                    bbox_right,\n",
    "                    bbox_bottom\n",
    "                )\n",
    "\n",
    "                unique_coco_annotation = {\n",
    "                    \"image_id\": i,\n",
    "                    \"bbox\": new_bbox,\n",
    "                    \"id\": j,\n",
    "                    \"category_id\": 0,\n",
    "                    \"segmentation\": [],\n",
    "                    \"area\": 0,\n",
    "                    \"iscrowd\": 0\n",
    "                }\n",
    "\n",
    "                d[\"annotations\"].append(unique_coco_annotation)\n",
    "                \n",
    "                j += 1\n",
    "\n",
    "        # IMAGES\n",
    "        image = Image.open(path + \"/image/\" + item)\n",
    "        height = image.size[1]\n",
    "        width = image.size[0]\n",
    "        id = i\n",
    "        license = 0\n",
    "        file_name = item\n",
    "\n",
    "        unique_coco_image = {\n",
    "            \"id\": id,\n",
    "            \"file_name\": file_name,\n",
    "            \"width\": width,\n",
    "            \"height\": height,\n",
    "            \"license\": license\n",
    "        }\n",
    "\n",
    "        d[\"images\"].append(unique_coco_image)\n",
    "\n",
    "        i += 1\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_as_coco = convert2coco(\"crowd4access-images/crowd4access-images/trainval\")\n",
    "test_data_as_coco = convert2coco(\"test_images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dump to a `.json` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"crowd4access-images/crowd4access-images/trainval/image/custom_train.json\", \"w\") as f:\n",
    "    json.dump(data_as_coco, f)\n",
    "\n",
    "with open(\"crowd4access-images/crowd4access-images/test/image/custom_test.json\",\"w\") as f:\n",
    "    json.dump(test_data_as_coco, f)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "54f27dbf71bc2c90a1f2b322f4ce0a9df234c73573728f17c171d088ff0f0d90"
  },
  "kernelspec": {
   "display_name": "Python 3.7.12 ('tactile-paving')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
